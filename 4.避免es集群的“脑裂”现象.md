### ES脑裂问题

es集群由多个**数据节点**和一个**主节点**（可以有多个备选主节点）组成。其中数据节点负责数据存储和具体操作，如执行搜索、聚合等任务，计算压力较大。主节点负责创建、删除索引、分配分片、追踪集群中的节点状态等工作，计算压力较轻。

正常情况下，当主节点无法工作时，会从备选主节点中选举一个出来变成新主节点，原主节点回归后变成备选主节点。但有时因为网络抖动等原因，主节点没能及时响应，集群误以为主节点挂了，选举了一个新主节点，此时一个es集群中有了两个主节点，其他节点不知道该听谁的调度，结果将是灾难性的！这种类似一个人得了精神分裂症，就被称之为“脑裂”现象。

造成es“脑裂”的因素有以下几个：

1、网络抖动

​        内网一般不会出现es集群的脑裂问题，可以监控内网流量状态。外网的网络出现问题的可能性大些。

2、节点负载

​        如果主节点同时承担数据节点的工作，可能会因为工作负载大而导致对应的 ES 实例停止响。

3、内存回收

​        由于数据节点上es进程占用的内存较大，较大规模的内存回收操作也能造成es进程失去响应。

避免es“脑裂”的措施主要有以下三个：

1、不要把主节点同时设为数据节点（node.master和node.data不要同时设为true）

2、将节点响应超时（discovery.zen.ping_timeout）稍稍设置长一些（默认是3秒），避免误判。

3、设置需要超过半数的备选节点同意，才能发生主节点重选，类似需要参议院半数以上通过，才能弹劾现任总统。（discovery.zen.minimum_master_nodes = 半数以上备选主节点数